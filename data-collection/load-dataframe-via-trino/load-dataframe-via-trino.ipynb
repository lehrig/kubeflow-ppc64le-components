{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f20b995-81e6-46ae-952a-f36267ee6cea",
   "metadata": {},
   "source": [
    "# Load Dataframe via Trino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "266a528d-a77c-460d-8b4c-3632170c702c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lab_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext lab_black\n"
     ]
    }
   ],
   "source": [
    "from kfp.components import create_component_from_func, OutputPath\n",
    "from typing import List\n",
    "\n",
    "%load_ext lab_black\n",
    "\n",
    "BASE_IMAGE = \"quay.io/ibm/kubeflow-notebook-image-ppc64le:latest\"\n",
    "\n",
    "\n",
    "def Load_Dataframe_via_Trino(\n",
    "    query: str,\n",
    "    dataframe_file: OutputPath(str),\n",
    "    columns: List[str],\n",
    "    columns_query: str = None,\n",
    "    host: str = \"trino.trino\",\n",
    "    port: int = 8080,\n",
    "    user: str = \"anybody\",\n",
    "    catalog: str = None,\n",
    "    schema: str = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Load a Pandas Dataframe using Trino as SQL client.\n",
    "\n",
    "            Parameters:\n",
    "                    query: An ANSI SQL compliant query for data, as supported by Trino. Queries can either use explicit or implicit references to schemata and catalogs. In the implicit case, the parameters catalog and schema must be set. Example: \"SELECT * FROM transactions OFFSET 20\".\n",
    "                    columns: List of column names of the resulting Dataframe.\n",
    "                    columns_query: An ANSI SQL compliant \"SHOW COLUMNS\" query for data columns, as supported by Trino. Queries can either use explicit or implicit references to schemata and catalogs. In the implicit case, the parameters catalog and schema must be set. If not set, generic column names are used. Example: \"SHOW COLUMNS FROM postgresql.public.transactions\".\n",
    "                    host: Host of the trino installation, typically the trino service in the trino namespace. Example:  \"trino.trino\".\n",
    "                    port: Trino service port. Example: \"8080\".\n",
    "                    user: Sets the query context to the given user. The user needs permissions to access the targeted catalog and schema. Example: \"anybody\".\n",
    "                    catalog: Sets the query context to the given catalog. If None, the query must explicitly reference to schemata and catalogs. If set, also a schema must be set. Example: \"postgresql\".\n",
    "                    schema: Sets the query context to the given schema. If None, the query must explicitly reference to schemata and catalogs. If set, also a catalog must be set. Example: \"public\".\n",
    "            Returns:\n",
    "                    dataframe_file: A Pandas dataframe containing the query results.\n",
    "    \"\"\"\n",
    "    import logging\n",
    "    import pandas as pd\n",
    "    import sys\n",
    "    from trino.dbapi import Connection\n",
    "\n",
    "    logging.basicConfig(\n",
    "        stream=sys.stdout,\n",
    "        level=logging.INFO,\n",
    "        format=\"%(levelname)s %(asctime)s: %(message)s\",\n",
    "    )\n",
    "\n",
    "    if (catalog is not None and schema is None) or (\n",
    "        catalog is None and schema is not None\n",
    "    ):\n",
    "        raise Exception(\n",
    "            f\"If you set one, you need to set both: catalog={catalog} but schema={schema}!\"\n",
    "        )\n",
    "\n",
    "    logging.info(\"Establishing Trino connection...\")\n",
    "    with Connection(\n",
    "        host=host,\n",
    "        port=port,\n",
    "        user=user,\n",
    "        catalog=catalog,\n",
    "        schema=schema,\n",
    "    ) as conn:\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        logging.info(\"Querying data...\")\n",
    "        cursor.execute(query)\n",
    "        dataframe = pd.DataFrame(cursor.fetchall())\n",
    "        logging.info(f\"Retrieved {len(dataframe)} rows.\")\n",
    "\n",
    "        if columns is not None:\n",
    "            logging.info(\"Using given column names...\")\n",
    "        elif columns_query is not None:\n",
    "            logging.info(\"Querying column names...\")\n",
    "            cursor.execute(columns_query)\n",
    "            columns_dataframe = pd.DataFrame(cursor.fetchall())\n",
    "            columns = columns_dataframe[0].values.tolist()\n",
    "        else:\n",
    "            logging.info(\"Creating generic column names...\")\n",
    "            columns = []\n",
    "            for column in range(dataframe.columns.size):\n",
    "                columns.append(f\"column_{column}\")\n",
    "\n",
    "        dataframe.columns = columns\n",
    "        logging.info(f\"Using columns: {columns}\")\n",
    "\n",
    "    # Feather outperforms Pickle & Parquet\n",
    "    # See https://towardsdatascience.com/the-best-format-to-save-pandas-data-414dca023e0d\n",
    "    dataframe.to_feather(dataframe_file)\n",
    "    logging.info(\"Finished.\")\n",
    "\n",
    "\n",
    "load_dataframe_via_trino_comp = create_component_from_func(\n",
    "    func=Load_Dataframe_via_Trino,\n",
    "    output_component_file=\"component.yaml\",\n",
    "    base_image=BASE_IMAGE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdfb67d-371d-4d48-bdd4-7db8789ed185",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
