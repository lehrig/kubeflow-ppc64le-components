{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f20b995-81e6-46ae-952a-f36267ee6cea",
   "metadata": {},
   "source": [
    "# Load Huggingface Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "266a528d-a77c-460d-8b4c-3632170c702c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lab_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext lab_black\n"
     ]
    }
   ],
   "source": [
    "from kfp.components import create_component_from_func, OutputPath\n",
    "from typing import Dict, List, NamedTuple\n",
    "\n",
    "%load_ext lab_black\n",
    "\n",
    "BASE_IMAGE = \"quay.io/ibm/kubeflow-notebook-image-ppc64le:latest\"\n",
    "\n",
    "\n",
    "def Load_HuggingFace_Dataset(\n",
    "    path: str,\n",
    "    dataset_dir: OutputPath(str),\n",
    "    configuration: str = \"\",\n",
    "    split: str = None,\n",
    "    label_columns: List[str] = None,\n",
    ") -> NamedTuple(\"LoadDatasetOutput\", [(\"labels\", Dict[str, List[str]])]):\n",
    "    \"\"\"\n",
    "    Load a Huggingface Dataset.\n",
    "\n",
    "            Parameters:\n",
    "                    path: Path from which to load the dataset. Huggingfaces hub for datasets is supported. Example: \"Lehrig/Monkey-Species-Collection\".\n",
    "                    dataset_dir: Target directory where the dataset will be loaded to. Should be available as a mount from a PVC. Example: \"/blackboard/dataset\".\n",
    "                    configuration: Name of the dataset configuration to load. Example: \"downsized\".\n",
    "                    split: Split within the dataset. If None, all splits are loaded as a DatasetDict. Example: \"train\",\n",
    "                    label_columns: Optional list of label column names to be fetched as optional, additional output. Example: [\"label\"].\n",
    "            Returns:\n",
    "                    labels: Dictionary mapping label columns to associated labels, if available. Empty dictionary otherwise. Example: {\"labels\": [\"cat\", \"dog\"]}\n",
    "    \"\"\"\n",
    "\n",
    "    from collections import namedtuple\n",
    "    from datasets import load_dataset\n",
    "    from datasets.dataset_dict import DatasetDict\n",
    "    import logging\n",
    "    import os\n",
    "    from PIL.Image import Image\n",
    "    import sys\n",
    "\n",
    "    logging.basicConfig(\n",
    "        stream=sys.stdout,\n",
    "        level=logging.INFO,\n",
    "        format=\"%(levelname)s %(asctime)s: %(message)s\",\n",
    "    )\n",
    "\n",
    "    if not configuration:\n",
    "        configuration = None\n",
    "    logging.info(\n",
    "        f\"Loading dataset from '{path}' using configuration '{configuration}'...\"\n",
    "    )\n",
    "    dataset = load_dataset(path=path, name=configuration, split=split)\n",
    "\n",
    "    logging.info(\"Reading image files into bytes...\")\n",
    "\n",
    "    # see: https://huggingface.co/docs/datasets/v2.4.0/en/package_reference/main_classes#datasets.Dataset.save_to_disk\n",
    "    def read_image_file(example):\n",
    "        for column in example:\n",
    "            if isinstance(example[column], Image):\n",
    "                with open(example[column].filename, \"rb\") as f:\n",
    "                    example[column] = {\"bytes\": f.read()}\n",
    "        return example\n",
    "\n",
    "    # note: batching in map caused caching issues, so not using it for now\n",
    "    dataset = dataset.map(read_image_file)\n",
    "\n",
    "    logging.info(f\"Saving dataset to '{dataset_dir}'...\")\n",
    "    if not os.path.exists(dataset_dir):\n",
    "        os.makedirs(dataset_dir)\n",
    "    dataset.save_to_disk(dataset_dir)\n",
    "\n",
    "    logging.info(f\"Dataset saved. Contents of '{dataset_dir}':\")\n",
    "    logging.info(os.listdir(dataset_dir))\n",
    "\n",
    "    labels = dict()\n",
    "    if label_columns is not None:\n",
    "        if isinstance(dataset, DatasetDict):\n",
    "            dataset = next(iter(dataset.values()))\n",
    "        for label_column in label_columns:\n",
    "            logging.info(f\"Fetching labels from column '{label_column}'...\")\n",
    "            labels[label_column] = dataset.features[label_column].names\n",
    "\n",
    "    output = namedtuple(\"LoadDatasetOutput\", [\"labels\"])\n",
    "\n",
    "    logging.info(\"Finished.\")\n",
    "    return output(labels)\n",
    "\n",
    "\n",
    "load_huggingface_dataset_comp = create_component_from_func(\n",
    "    func=Load_HuggingFace_Dataset,\n",
    "    output_component_file=\"component.yaml\",\n",
    "    base_image=BASE_IMAGE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee82e67-5174-4941-8367-1937ad33906c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
