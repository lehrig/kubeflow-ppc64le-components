{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Evidently and Kubeflow Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp.components import InputPath, OutputPath, create_component_from_func\n",
    "import kfp\n",
    "from kfp import components\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "from evidently import ColumnMapping\n",
    "\n",
    "from evidently.report import Report\n",
    "from evidently.metric_preset import *\n",
    "from evidently.metric_preset import TargetDriftPreset\n",
    "\n",
    "from evidently.test_suite import TestSuite\n",
    "from evidently.test_preset import DataStabilityTestPreset\n",
    "from evidently.tests import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Valid/Test sizes: 318 80 171\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Gets and split dataset\n",
    "data = load_breast_cancer(as_frame=True)\n",
    "X, y = data.data, data.target\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = \\\n",
    "    train_test_split(X, y, test_size=0.3, random_state=123)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = \\\n",
    "    train_test_split(X_temp, y_temp, test_size=0.2, random_state=123)\n",
    "\n",
    "print('Train/Valid/Test sizes:', y_train.shape[0], y_valid.shape[0], y_test.shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adamshedivy/mambaforge/envs/kubeflow/lib/python3.10/site-packages/evidently/metrics/data_integrity/dataset_missing_values_metric.py:147: FutureWarning:\n",
      "\n",
      "elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = X.copy(deep=True)\n",
    "dataset['target'] = y\n",
    "\n",
    "report = Report(metrics=[\n",
    "    DataQualityPreset()\n",
    "])\n",
    "\n",
    "report.run(current_data=dataset, reference_data=None)\n",
    "report.save_html('test-decision-tree.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_target = X_train.copy(deep=True)\n",
    "\n",
    "X_train_target['target'] = y.loc[X_train_target.index]\n",
    "\n",
    "X_valid_target = X_valid.copy(deep=True)\n",
    "X_valid_target['target'] = y.loc[X_valid_target.index]\n",
    "\n",
    "num_target_drift_report = Report(metrics=[\n",
    "    TargetDriftPreset(),\n",
    "])\n",
    "\n",
    "num_target_drift_report.run(reference_data=X_train_target, current_data=X_valid_target)\n",
    "num_target_drift_report.save_html('num_target_drift_report.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_drift_report = Report(metrics=[\n",
    "    DataDriftPreset(),\n",
    "])\n",
    "\n",
    "data_drift_report.run(reference_data=X_train, current_data=X_valid)\n",
    "data_drift_report.save_html('data_drift_report.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.loc[:, dataset.columns != 'target'].head()\n",
    "dataset['target'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.00\n",
      "Validation Accuracy: 0.96\n",
      "Test Accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "boost = GradientBoostingClassifier(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    max_depth=8,\n",
    "    random_state=1)\n",
    "\n",
    "boost.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "print(\"Training Accuracy: %0.2f\" % boost.score(X_train, y_train))\n",
    "print(\"Validation Accuracy: %0.2f\" % boost.score(X_valid, y_valid))\n",
    "print(\"Test Accuracy: %0.2f\" % boost.score(X_test, y_test))\n",
    "\n",
    "with open('test.txt', 'w') as f:\n",
    "    f.write(\"Training Accuracy: %0.2f\\n\" % boost.score(X_train, y_train))\n",
    "    f.write(\"Validation Accuracy: %0.2f\\n\" % boost.score(X_valid, y_valid))\n",
    "    f.write(\"Test Accuracy: %0.2f\\n\" % boost.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>prediction</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>6.981</td>\n",
       "      <td>13.43</td>\n",
       "      <td>43.79</td>\n",
       "      <td>143.5</td>\n",
       "      <td>0.11700</td>\n",
       "      <td>0.07568</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1930</td>\n",
       "      <td>0.07818</td>\n",
       "      <td>...</td>\n",
       "      <td>50.41</td>\n",
       "      <td>185.2</td>\n",
       "      <td>0.1584</td>\n",
       "      <td>0.1202</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2932</td>\n",
       "      <td>0.09382</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>16.260</td>\n",
       "      <td>21.88</td>\n",
       "      <td>107.50</td>\n",
       "      <td>826.8</td>\n",
       "      <td>0.11650</td>\n",
       "      <td>0.12830</td>\n",
       "      <td>0.1799</td>\n",
       "      <td>0.07981</td>\n",
       "      <td>0.1869</td>\n",
       "      <td>0.06532</td>\n",
       "      <td>...</td>\n",
       "      <td>113.70</td>\n",
       "      <td>975.2</td>\n",
       "      <td>0.1426</td>\n",
       "      <td>0.2116</td>\n",
       "      <td>0.3344</td>\n",
       "      <td>0.1047</td>\n",
       "      <td>0.2736</td>\n",
       "      <td>0.07953</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>19.070</td>\n",
       "      <td>24.81</td>\n",
       "      <td>128.30</td>\n",
       "      <td>1104.0</td>\n",
       "      <td>0.09081</td>\n",
       "      <td>0.21900</td>\n",
       "      <td>0.2107</td>\n",
       "      <td>0.09961</td>\n",
       "      <td>0.2310</td>\n",
       "      <td>0.06343</td>\n",
       "      <td>...</td>\n",
       "      <td>177.40</td>\n",
       "      <td>1651.0</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>0.7444</td>\n",
       "      <td>0.7242</td>\n",
       "      <td>0.2493</td>\n",
       "      <td>0.4670</td>\n",
       "      <td>0.10380</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>20.180</td>\n",
       "      <td>19.54</td>\n",
       "      <td>133.80</td>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.11330</td>\n",
       "      <td>0.14890</td>\n",
       "      <td>0.2133</td>\n",
       "      <td>0.12590</td>\n",
       "      <td>0.1724</td>\n",
       "      <td>0.06053</td>\n",
       "      <td>...</td>\n",
       "      <td>146.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.1665</td>\n",
       "      <td>0.2942</td>\n",
       "      <td>0.5308</td>\n",
       "      <td>0.2173</td>\n",
       "      <td>0.3032</td>\n",
       "      <td>0.08075</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>10.950</td>\n",
       "      <td>21.35</td>\n",
       "      <td>71.90</td>\n",
       "      <td>371.1</td>\n",
       "      <td>0.12270</td>\n",
       "      <td>0.12180</td>\n",
       "      <td>0.1044</td>\n",
       "      <td>0.05669</td>\n",
       "      <td>0.1895</td>\n",
       "      <td>0.06870</td>\n",
       "      <td>...</td>\n",
       "      <td>87.22</td>\n",
       "      <td>514.0</td>\n",
       "      <td>0.1909</td>\n",
       "      <td>0.2698</td>\n",
       "      <td>0.4023</td>\n",
       "      <td>0.1424</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>0.09606</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "101        6.981         13.43           43.79      143.5          0.11700   \n",
       "329       16.260         21.88          107.50      826.8          0.11650   \n",
       "42        19.070         24.81          128.30     1104.0          0.09081   \n",
       "432       20.180         19.54          133.80     1250.0          0.11330   \n",
       "41        10.950         21.35           71.90      371.1          0.12270   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "101           0.07568          0.0000              0.00000         0.1930   \n",
       "329           0.12830          0.1799              0.07981         0.1869   \n",
       "42            0.21900          0.2107              0.09961         0.2310   \n",
       "432           0.14890          0.2133              0.12590         0.1724   \n",
       "41            0.12180          0.1044              0.05669         0.1895   \n",
       "\n",
       "     mean fractal dimension  ...  worst perimeter  worst area  \\\n",
       "101                 0.07818  ...            50.41       185.2   \n",
       "329                 0.06532  ...           113.70       975.2   \n",
       "42                  0.06343  ...           177.40      1651.0   \n",
       "432                 0.06053  ...           146.00      1479.0   \n",
       "41                  0.06870  ...            87.22       514.0   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "101            0.1584             0.1202           0.0000   \n",
       "329            0.1426             0.2116           0.3344   \n",
       "42             0.1247             0.7444           0.7242   \n",
       "432            0.1665             0.2942           0.5308   \n",
       "41             0.1909             0.2698           0.4023   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  \\\n",
       "101                0.0000          0.2932                  0.09382   \n",
       "329                0.1047          0.2736                  0.07953   \n",
       "42                 0.2493          0.4670                  0.10380   \n",
       "432                0.2173          0.3032                  0.08075   \n",
       "41                 0.1424          0.2964                  0.09606   \n",
       "\n",
       "     prediction  target  \n",
       "101           1       1  \n",
       "329           0       0  \n",
       "42            0       0  \n",
       "432           0       0  \n",
       "41            0       0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = boost.predict(X_test)\n",
    "X_test_results = X_test.copy(deep=True)\n",
    "X_test_results['prediction'] = y_pred\n",
    "X_test_results['target'] = y_test\n",
    "X_test_results.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report = Report(\n",
    "    metrics=[ClassificationPreset()]\n",
    ")\n",
    "\n",
    "classification_report.run(reference_data=None, current_data=X_test_results)\n",
    "classification_report.save_html('classification_report.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(\n",
    "    output_path: OutputPath('CSV'),\n",
    ") -> None:\n",
    "    \n",
    "    from sklearn.datasets import load_breast_cancer\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    import pandas as pd\n",
    "    from pathlib import Path\n",
    "        \n",
    "    # Gets and split dataset\n",
    "    data = load_breast_cancer(as_frame=True)\n",
    "    X, y = data.data, data.target\n",
    "    \n",
    "    dataset = X.copy(deep=True)\n",
    "    dataset['target'] = y\n",
    "    \n",
    "    Path(output_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    dataset.to_csv(output_path)\n",
    "    \n",
    "download_data_op = create_component_from_func(\n",
    "    download_data,\n",
    "    output_component_file='download_breast_cancer_data.yaml',\n",
    "    base_image='quay.io/ibm/kubeflow-notebook-image-ppc64le:latest',\n",
    "    annotations={\n",
    "        'author':'Adam Shedivy'\n",
    "    }\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_op(\n",
    "    input_path: InputPath('CSV'),\n",
    "    output_path: OutputPath('JSON'),\n",
    "    test_size: float = 0.2,\n",
    "    random_sate: int = 123,\n",
    ") -> None:\n",
    "    \n",
    "    import json\n",
    "    import pandas as pd\n",
    "    from pathlib import Path\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    df = pd.read_csv(input_path)\n",
    "    \n",
    "    X, y = df.loc[:, df.columns != 'target'], df['target']\n",
    "    \n",
    "    X_temp, X_test, y_temp, y_test = \\\n",
    "        train_test_split(X, y, test_size=0.3, random_state=random_sate, stratify=y)\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = \\\n",
    "        train_test_split(X_temp, y_temp, test_size=test_size, random_state=random_sate, stratify=y_temp)\n",
    "        \n",
    "    DATA = {\n",
    "        'X_train': X_train.to_dict(),\n",
    "        'X_valid': X_valid.to_dict(),\n",
    "        'y_train': y_train.to_dict(),\n",
    "        'y_valid': y_valid.to_dict()\n",
    "    }\n",
    "    \n",
    "    json_data = json.dumps(DATA)\n",
    "    \n",
    "    Path(output_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(output_path, 'w') as f:\n",
    "        f.write(json_data)\n",
    "        \n",
    "train_test_split_op = create_component_from_func(\n",
    "    train_test_split_op,\n",
    "    output_component_file='train_test_split.yaml',\n",
    "    base_image='quay.io/ibm/kubeflow-notebook-image-ppc64le:latest',\n",
    "    packages_to_install=['pandas', 'scikit-learn']\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gradient_boost(\n",
    "    data_path: InputPath('JSON'),\n",
    "    output_path: OutputPath(str),\n",
    ") -> None:\n",
    "    \n",
    "    import json\n",
    "    from pathlib import Path    \n",
    "    import pandas as pd\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    \n",
    "    with open(data_path, 'r') as f:\n",
    "        data = json.loads(f.read())\n",
    "    \n",
    "    X_train = pd.DataFrame.from_dict(data['X_train'])\n",
    "    X_valid = pd.DataFrame.from_dict(data['X_valid'])\n",
    "    y_train = pd.DataFrame.from_dict(data['y_train'])\n",
    "    y_valid = pd.DataFrame.from_dict(data['y_valid'])\n",
    "    \n",
    "\n",
    "\n",
    "    boost = GradientBoostingClassifier(\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=100,\n",
    "        max_depth=8,\n",
    "        random_state=1)\n",
    "\n",
    "    boost.fit(X_train, y_train)\n",
    "        \n",
    "        \n",
    "    # print(\"Training Accuracy: %0.2f\" % boost.score(X_train, y_train))\n",
    "    # print(\"Validation Accuracy: %0.2f\" % boost.score(X_valid, y_valid))\n",
    "    # print(\"Test Accuracy: %0.2f\" % boost.score(X_test, y_test))\n",
    "    \n",
    "    Path.mkdir(output_path.parent, parents=True, exist_ok=True)\n",
    "    with open(output_path, 'w') as f:\n",
    "        f.write(\"Training Accuracy: %0.2f\\n\" % boost.score(X_train, y_train))\n",
    "        f.write(\"Validation Accuracy: %0.2f\\n\" % boost.score(X_valid, y_valid))\n",
    "        f.write(\"Test Accuracy: %0.2f\\n\" % boost.score(X_test, y_test))\n",
    "        \n",
    "\n",
    "run_gradient_boost_op = create_component_from_func(\n",
    "    run_gradient_boost,\n",
    "    output_component_file='run_gradient_boost.yaml',\n",
    "    base_image='quay.io/ibm/kubeflow-notebook-image-ppc64le:latest',\n",
    "    packages_to_install=[\n",
    "        'scikit-learn'\n",
    "    ]\n",
    ")\n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline definition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EXAMPLES = os.path.abspath(\"\")\n",
    "ROOT = os.path.dirname(EXAMPLES)\n",
    "EVIDENTLY = os.path.join(ROOT, 'evidently')\n",
    "DATA_QUALITY = os.path.join(EVIDENTLY, 'data-quality-report')\n",
    "HTML_VIEW = os.path.join(ROOT, 'html-viewer')\n",
    "\n",
    "download_data_op = components.load_component_from_file('download_breast_cancer_data.yaml')\n",
    "train_test_split_op = components.load_component_from_file('train_test_split.yaml')\n",
    "run_gradient_boost_op = components.load_component_from_file('run_gradient_boost.yaml')\n",
    "data_quality_op = components.load_component_from_file(os.path.join(DATA_QUALITY, 'component.yaml'))\n",
    "html_view_op = components.load_component_from_file(os.path.join(HTML_VIEW, 'component.yaml'))\n",
    "\n",
    "\n",
    "@kfp.dsl.pipeline(name='test-pipeline')\n",
    "def test_pipeline():\n",
    "    data = download_data_op().output\n",
    "    \n",
    "    report = data_quality_op(\n",
    "        cur=data\n",
    "    ).output\n",
    "    \n",
    "    html_view_op(\n",
    "        html=report\n",
    "    )\n",
    "    \n",
    "    prepared_data = train_test_split_op(\n",
    "        input=data\n",
    "    )\n",
    "\n",
    "    \n",
    "    run_gradient_boost = run_gradient_boost_op(\n",
    "        data=prepared_data.outputs\n",
    "    )\n",
    "    \n",
    "kfp_endpoint=None\n",
    "kfp.compiler.Compiler().compile(test_pipeline, 'testPipeline.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kubeflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cfa3bc2375f864739603e288c05d4bfd658f5dbc82f0120480866d89037421e0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
